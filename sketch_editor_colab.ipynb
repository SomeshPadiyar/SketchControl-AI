# ==============================================================================
# üé® SketchControl-AI: Sketch-Guided Image Generation & Editing
#
# This notebook runs a minimal, all-in-one web application (powered by Gradio)
# that combines Stable Diffusion ControlNet (Scribble) for initial generation
# and Stable Diffusion Inpainting for editing, all on a free Google Colab GPU.
#
# Click "Runtime" -> "Change runtime type" -> Select "GPU" before starting.
# ==============================================================================

# ----------------------------
# 1. INSTALLATION & SETUP
# ----------------------------
# Install necessary dependencies, including the diffusers library and auxiliary ControlNet tools.
# We also install xformers for memory optimization on the allocated GPU.
!pip install -q diffusers accelerate controlnet_aux transformers gradio Pillow
!pip install -q xformers || true

# Set environment variable to prevent the Matplotlib backend ValueError on launch
import os
os.environ["MPLBACKEND"] = "Agg"

from IPython.display import clear_output
clear_output()
print("Dependencies installed successfully. Running imports...")

# ----------------------------
# 2. IMPORTS & MODEL DEFINITIONS
# ----------------------------
import torch
import numpy as np
from PIL import Image, ImageDraw
import gradio as gr
from diffusers import (
    StableDiffusionInpaintPipeline,
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    UniPCMultistepScheduler,
)
from controlnet_aux import HEDdetector

# --- Device Setup ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")


# ----------------------------
# 3. MODEL LOADING
# ----------------------------
print("Loading core models (may take a minute)...")
inpaint_pipe = None
controlnet_pipe = None
scribble_processor = None

# Helper function for UI messages
def make_text_image(msg: str, size=(512, 512), bg=(255, 220, 180), fg=(0, 0, 0)):
    img = Image.new("RGB", size, color=bg)
    draw = ImageDraw.Draw(img)
    y = 8
    for line in msg.splitlines():
        draw.text((8, y), line, fill=fg)
        y += 12
    return img

# --- Load Inpaint Pipeline (for editing) ---
try:
    inpaint_pipe = StableDiffusionInpaintPipeline.from_pretrained(
        "runwayml/stable-diffusion-inpainting",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
    )
    inpaint_pipe.scheduler = UniPCMultistepScheduler.from_config(inpaint_pipe.scheduler.config)
    if device == "cuda":
        inpaint_pipe = inpaint_pipe.to(device)
        try:
            inpaint_pipe.enable_xformers_memory_efficient_attention()
        except:
            pass
    print("‚úì Inpaint Pipeline Loaded.")
except Exception as e:
    print(f"Error loading inpaint pipeline: {e}")

# --- Load ControlNet Pipeline (for sketch->image) ---
try:
    controlnet_scribble = ControlNetModel.from_pretrained(
        "lllyasviel/control_v11p_sd15_scribble", 
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    )
    controlnet_pipe = StableDiffusionControlNetPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        controlnet=controlnet_scribble,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
    )
    controlnet_pipe.scheduler = UniPCMultistepScheduler.from_config(controlnet_pipe.scheduler.config)
    if device == "cuda":
        controlnet_pipe = controlnet_pipe.to(device)
        try:
            controlnet_pipe.enable_xformers_memory_efficient_attention()
        except:
            pass
    print("‚úì ControlNet Pipeline Loaded.")
except Exception as e:
    print(f"Error loading ControlNet pipeline: {e}")

# --- Load HED Detector (Scribble Preprocessor) ---
try:
    scribble_processor = HEDdetector.from_pretrained("lllyasviel/Annotators")
    print("‚úì HEDdetector Loaded.")
except Exception as e:
    print(f"Error loading HEDdetector: {e}")


# ----------------------------
# 4. CORE LOGIC (GENERATION FUNCTION)
# ----------------------------
# robust input parser for Gradio ImageEditor nested data
def extract_images(data):
    """Extracts image (RGB PIL) and mask (L PIL) from Gradio ImageEditor output."""
    img = None
    mask = None

    if data is None: return None, None
    if isinstance(data, Image.Image): return data.convert("RGB"), None
    if isinstance(data, np.ndarray): return Image.fromarray(data).convert("RGB"), None

    if isinstance(data, dict):
        if "image" in data and isinstance(data["image"], Image.Image):
            img = data["image"].convert("RGB")
        if "mask" in data and isinstance(data["mask"], Image.Image):
            try:
                mask = data["mask"].convert("L")
            except Exception:
                mask = None
        if img is None and "layers" in data:
            for layer in data["layers"]:
                i, m = extract_images(layer)
                if i is not None and img is None: img = i
                if m is not None and mask is None: mask = m

    if isinstance(data, (list, tuple)):
        for elem in data:
            i, m = extract_images(elem)
            if i is not None and img is None: img = i
            if m is not None and mask is None: mask = m

    return img, mask

@torch.no_grad()
def generate_image(gr_input, prompt: str, steps: int, guidance_scale: float, inpaint_strength: float, sketch_mode: bool):
    if controlnet_pipe is None or inpaint_pipe is None or scribble_processor is None:
        return make_text_image("Model(s) not ready. Please check Colab logs for errors.")

    input_image, mask_image = extract_images(gr_input)
    if input_image is None:
        return make_text_image("No input image found. Please draw or upload in the left panel.")

    input_image = input_image.convert("RGB")

    # Determine which mode to use: Sketch Mode (ControlNet) or Inpainting
    is_mask_present = mask_image is not None and mask_image.getbbox() is not None
    
    if sketch_mode or not is_mask_present:
        # --- SKETCH MODE (ControlNet) ---
        try:
            print("Running ControlNet (Scribble) mode...")
            # Create scribble control image (NumPy array output)
            scribble_np = scribble_processor(input_image, scribble=True, detect_resolution=512, image_resolution=512)
            
            # Run ControlNet pipeline
            out = controlnet_pipe(
                prompt=prompt,
                image=scribble_np,  # Pass NumPy array directly
                num_inference_steps=int(steps),
                guidance_scale=float(guidance_scale),
            ).images[0]
            return out
        except Exception as e:
            import traceback
            traceback.print_exc()
            return make_text_image(f"ControlNet Error: {type(e).__name__}: {str(e)}")
            
    else:
        # --- INPAINTING MODE (Editing) ---
        try:
            print("Running Inpainting mode...")
            out = inpaint_pipe(
                prompt=prompt,
                image=input_image,
                mask_image=mask_image,
                strength=float(inpaint_strength),
                num_inference_steps=int(steps),
                guidance_scale=float(guidance_scale),
            ).images[0]
            return out
        except Exception as e:
            import traceback
            traceback.print_exc()
            return make_text_image(f"Inpainting Error: {type(e).__name__}: {str(e)}")

# ----------------------------
# 5. GRADIO UI LAUNCH
# ----------------------------
with gr.Blocks(css="#output_image {max-width: 512px;}") as demo:
    gr.Markdown("# ‚úèÔ∏è SketchControl-AI: Guided Image Generator\n\n**Usage:** Draw a shape and check 'Sketch Mode' to generate, or upload an image and paint a mask (uncheck 'Sketch Mode') to edit.")
    
    with gr.Row():
        with gr.Column():
            input_editor = gr.ImageEditor(label="Draw or Upload (Input Image)", type="pil", image_mode="RGB", interactive=True, width=512, height=512, brush={'color': '#FF0000', 'size': 12, 'mask': 'black'})
            prompt_box = gr.Textbox(label="Text Prompt", value="A photorealistic red apple on a white background, studio lighting")
            sketch_toggle = gr.Checkbox(label="Sketch Mode (ControlNet)", value=True, info="If checked, uses the sketch structure for generation. If unchecked, uses the painted mask for editing.")
            run_btn = gr.Button("Generate / Edit", variant="primary")
            
        with gr.Column():
            out_im = gr.Image(label="Generated Image", width=512, height=512)
            steps_slider = gr.Slider(label="Steps", minimum=10, maximum=50, value=30, step=1, info="Number of sampling steps.")
            cfg_slider = gr.Slider(label="Guidance Scale", minimum=3.0, maximum=15.0, value=7.5, step=0.5, info="How strictly the output follows the prompt.")
            strength_slider = gr.Slider(label="Inpaint Strength (Editing Only)", minimum=0.5, maximum=1.0, value=0.9, step=0.05, info="How much to change the masked area (Higher = more change).")

    run_btn.click(
        fn=generate_image, 
        inputs=[input_editor, prompt_box, steps_slider, cfg_slider, strength_slider, sketch_toggle], 
        outputs=out_im
    )

print("\nLaunching app via Gradio...")
demo.launch(share=True)
