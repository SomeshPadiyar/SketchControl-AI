# ======================================================================
# ðŸŽ¨ Sketch-Guided Image Generator
# Combines ControlNet (sketch â†’ image) and Stable Diffusion Inpainting
# Provides "Copy to Sketch" to reuse generated images as sketches
# ======================================================================

import os
import torch
import numpy as np
from PIL import Image, ImageDraw
import gradio as gr
from diffusers import (
    StableDiffusionInpaintPipeline,
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    UniPCMultistepScheduler,
)
from controlnet_aux import HEDdetector

# ----------------------------------------------------------------------
# Basic text-to-image utility (used to display error/info messages)
# ----------------------------------------------------------------------
def make_text_image(msg: str, size=(512, 512), bg=(255, 220, 180), fg=(0, 0, 0)):
    img = Image.new("RGB", size, color=bg)
    draw = ImageDraw.Draw(img)
    y = 8
    for line in msg.splitlines():
        draw.text((8, y), line, fill=fg)
        y += 12
    return img


# ----------------------------------------------------------------------
# Environment setup
# ----------------------------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

print("Installing libs (if needed)...")
!pip install -q diffusers accelerate controlnet_aux transformers gradio Pillow
!pip install -q xformers || true

os.environ["MPLBACKEND"] = "Agg"


# ----------------------------------------------------------------------
# Model Loading
# ----------------------------------------------------------------------
inpaint_pipe = None
controlnet_pipe = None
scribble_processor = None

# Stable Diffusion Inpainting
try:
    inpaint_pipe = StableDiffusionInpaintPipeline.from_pretrained(
        "runwayml/stable-diffusion-inpainting",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
    )
    inpaint_pipe.scheduler = UniPCMultistepScheduler.from_config(inpaint_pipe.scheduler.config)
    if device == "cuda":
        inpaint_pipe = inpaint_pipe.to(device)
        inpaint_pipe.enable_xformers_memory_efficient_attention()
    print("Loaded inpaint pipeline.")
except Exception as e:
    print("Error loading inpaint pipeline:", e)

# ControlNet (Scribble)
try:
    controlnet_model = ControlNetModel.from_pretrained(
        "lllyasviel/control_v11p_sd15_scribble",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    )
    controlnet_pipe = StableDiffusionControlNetPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        controlnet=controlnet_model,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
    )
    controlnet_pipe.scheduler = UniPCMultistepScheduler.from_config(controlnet_pipe.scheduler.config)
    if device == "cuda":
        controlnet_pipe = controlnet_pipe.to(device)
        controlnet_pipe.enable_xformers_memory_efficient_attention()
    print("Loaded ControlNet pipeline.")
except Exception as e:
    print("Error loading ControlNet pipeline:", e)

# HED edge detector for sketch processing
try:
    scribble_processor = HEDdetector.from_pretrained("lllyasviel/Annotators")
    print("Loaded HEDdetector.")
except Exception as e:
    print("Error loading HEDdetector:", e)


# ----------------------------------------------------------------------
# Utility: Extract image and mask from Gradio ImageEditor data
# ----------------------------------------------------------------------
def extract_images(data):
    img, mask = None, None
    if data is None:
        return None, None
    if isinstance(data, Image.Image):
        return data.convert("RGB"), None
    if isinstance(data, np.ndarray):
        return Image.fromarray(data).convert("RGB"), None
    if isinstance(data, dict):
        if "image" in data and isinstance(data["image"], Image.Image):
            img = data["image"].convert("RGB")
        if "mask" in data and isinstance(data["mask"], Image.Image):
            try:
                mask = data["mask"].convert("L")
            except Exception:
                mask = None
        if img is None and "layers" in data:
            for layer in data["layers"]:
                i, m = extract_images(layer)
                img = img or i
                mask = mask or m
    if isinstance(data, (list, tuple)):
        for elem in data:
            i, m = extract_images(elem)
            img = img or i
            mask = mask or m
    return img, mask


# ----------------------------------------------------------------------
# Image generation (ControlNet or Inpainting)
# ----------------------------------------------------------------------
@torch.no_grad()
def generate_image(gr_input, prompt: str, steps: int, guidance_scale: float, inpaint_strength: float, sketch_mode: bool):
    if controlnet_pipe is None or inpaint_pipe is None or scribble_processor is None:
        return make_text_image("Model(s) not loaded properly. Check console logs.")

    input_image, mask_image = extract_images(gr_input)
    if input_image is None:
        return make_text_image("No input image found. Please draw or upload first.")
    input_image = input_image.convert("RGB")

    try:
        if sketch_mode or mask_image is None or mask_image.getbbox() is None:
            # Sketch â†’ Image via ControlNet
            scribble_np = scribble_processor(input_image, scribble=True, detect_resolution=512, image_resolution=512)
            return controlnet_pipe(
                prompt=prompt,
                image=scribble_np,
                num_inference_steps=int(steps),
                guidance_scale=float(guidance_scale),
            ).images[0]
        else:
            # Inpainting
            return inpaint_pipe(
                prompt=prompt,
                image=input_image,
                mask_image=mask_image,
                strength=float(inpaint_strength),
                num_inference_steps=int(steps),
                guidance_scale=float(guidance_scale),
            ).images[0]
    except Exception as e:
        import traceback
        tb = traceback.format_exc()
        return make_text_image(f"Generation error: {type(e).__name__}\n\n{tb}")


# ----------------------------------------------------------------------
# "Copy to Sketch" helper â€“ sends generated image back to editor
# ----------------------------------------------------------------------
def copy_to_sketch(generated_img):
    if generated_img is None:
        return None
    if isinstance(generated_img, Image.Image):
        return generated_img.convert("RGB")
    if isinstance(generated_img, np.ndarray):
        return Image.fromarray(generated_img).convert("RGB")
    return None


# ----------------------------------------------------------------------
# Gradio UI
# ----------------------------------------------------------------------
with gr.Blocks(css="#output_image {max-width: 512px;}") as demo:
    gr.Markdown("## ðŸŽ¨ AI Sketch-Guided Image Generator\n- ControlNet for sketch-to-image\n- Stable Diffusion Inpainting for edits")

    with gr.Row():
        with gr.Column():
            input_editor = gr.ImageEditor(label="Sketch / Upload", type="pil", image_mode="RGB", interactive=True, width=512, height=512)
            prompt_box = gr.Textbox(label="Prompt", value="A photorealistic red apple on a white background, studio lighting")
            sketch_toggle = gr.Checkbox(label="Tick for Sketch Mode (ControlNet) else editing mode (Inpainting)", value=True)
        with gr.Column():
            out_im = gr.Image(label="Generated Image", width=512, height=512)
            steps_slider = gr.Slider(label="Steps", minimum=10, maximum=50, value=30, step=1)
            cfg_slider = gr.Slider(label="Guidance Scale (The Prompt's Influence)", minimum=3.0, maximum=15.0, value=7.5, step=0.5)
            strength_slider = gr.Slider(label="Inpaint Strength (editing only)", minimum=0.5, maximum=1.0, value=0.9, step=0.05)
            run_btn = gr.Button("Generate")
            copy_btn = gr.Button("Copy to Sketch")

    run_btn.click(fn=generate_image, inputs=[input_editor, prompt_box, steps_slider, cfg_slider, strength_slider, sketch_toggle], outputs=out_im)
    copy_btn.click(fn=copy_to_sketch, inputs=[out_im], outputs=[input_editor])

print("Launching app...")
demo.launch(share=True)
